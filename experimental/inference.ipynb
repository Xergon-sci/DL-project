{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Not ideal but since it is only an excercise...\n",
    "PATH = r'/scratch/brussel/102/vsc10255/DL-project/experimental'\n",
    "PRODUCTION = os.path.join(PATH, os.pardir, 'production')\n",
    "sys.path.append(PRODUCTION)\n",
    "\n",
    "import logging\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "from models import LeNet5\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELPATH = os.path.join(PRODUCTION, 'runs', 'LeNet5_on_01-16-2022_14.39.36', 'LeNet5_on_01-16-2022_14.39.36', 'LeNet5_on_01-16-2022_14.39.36_inference.pt')\n",
    "IMAGEPATH = os.path.join(PATH, os.pardir, 'inference', 'images', '017.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert(x):\n",
    "    return 1-x\n",
    "\n",
    "def preprocess(image_path):\n",
    "\n",
    "    # Define a transformer for preprocessing\n",
    "    transformer = transforms.Compose([\n",
    "        # Resize to 32x32 as per the model\n",
    "        transforms.Resize(32),\n",
    "        # Images need to be grayscale aswel\n",
    "        transforms.Grayscale(),\n",
    "        \n",
    "        transforms.CenterCrop(20),\n",
    "        transforms.Resize(32),\n",
    "\n",
    "        # Conversion to tensor\n",
    "        transforms.ToTensor(),\n",
    "        lambda img: img.apply_(invert),\n",
    "    ])\n",
    "\n",
    "    # Load the image with PILLOW as this is what pyvision uses internally\n",
    "    im = Image.open(image_path)\n",
    "\n",
    "    return transformer(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = preprocess(IMAGEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b55c6caa250>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image, cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    log = logging.getLogger()\n",
    "    log.setLevel(logging.INFO)\n",
    "\n",
    "    formatter = logging.Formatter('%(asctime)s:%(levelname)s:%(message)s')\n",
    "\n",
    "    sh = logging.StreamHandler(sys.stdout)\n",
    "    sh.setLevel(logging.DEBUG)\n",
    "    sh.setFormatter(formatter)\n",
    "\n",
    "    log.addHandler(sh)\n",
    "\n",
    "    \n",
    "\n",
    "    LABEL_MAP = {\n",
    "        # not PEP8 formatted, but readable\n",
    "        0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9',\n",
    "        10: 'A', 11: 'B', 12: 'C', 13: 'D', 14: 'E', 15: 'F', 16: 'G', 17: 'H', 18: 'I', 19: 'J',\n",
    "        20: 'K', 21: 'L', 22: 'M', 23: 'N', 24: 'O', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'T',\n",
    "        30: 'U', 31: 'V', 32: 'W', 33: 'X', 34: 'Y', 35: 'Z',\n",
    "        36: 'a', 37: 'b', 38: 'd', 39: 'e',\n",
    "        40: 'f', 41: 'g', 42: 'h', 43: 'n', 44: 'q', 45: 'r', 46: 't',\n",
    "    }\n",
    "\n",
    "    logging.info(f'The used model is located at {MODELPATH}')\n",
    "    logging.info(f'The folder with images for which the predictions will be made is located at {IMAGEPATH}')\n",
    "\n",
    "    # load and preprocess the image\n",
    "    logging.info('Preprocessing the image')\n",
    "    image = preprocess(IMAGEPATH)\n",
    "\n",
    "    # the model expects batches, since we only have 1 image, we need to add a dimension for the batch\n",
    "    image = image.unsqueeze(0)\n",
    "\n",
    "    logging.info('Loading the model')\n",
    "    # get the network architecture\n",
    "    model = LeNet5(47)\n",
    "\n",
    "    # load the model weights etc. onto the CPU for portability\n",
    "    model.load_state_dict(torch.load(MODELPATH, map_location=torch.device('cpu')))\n",
    "\n",
    "    # make the prediction\n",
    "    logging.info('Predicting the label for the image')\n",
    "    output = model(image)\n",
    "\n",
    "    # Get the prediction which is most likely our target\n",
    "    values, prediction = torch.max(output.data, 1)\n",
    "\n",
    "    print(output.data)\n",
    "    print(prediction.item())\n",
    "    \n",
    "    # Translate the predicted value to a character\n",
    "    result = LABEL_MAP[prediction.item()]\n",
    "    logging.info('====================')\n",
    "    logging.info(f'The image represent a {result}.')\n",
    "    logging.info('====================')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
